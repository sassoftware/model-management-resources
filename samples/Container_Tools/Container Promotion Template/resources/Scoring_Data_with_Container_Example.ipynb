{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aa88d03",
   "metadata": {},
   "source": [
    "Copyright Â© 2022, SAS Institute Inc., Cary, NC, USA.  All Rights Reserved. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-strategy",
   "metadata": {},
   "source": [
    "# Scoring Data with Containerized Deployment over REST API\n",
    "## Table of Contents\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Gather Resources](#Gather-Resources)\n",
    "1. [Find the Container Endpoint](#Find-the-Container-Endpoint)\n",
    "1. [Prepare Data](#Prepare-Data)\n",
    "1. [Make REST API Calls](#Make-REST-API-Calls)\n",
    "    1. [Method 1: Sequential REST API Calls](#method1)\n",
    "    1. [Method 2: Parallel REST API Calls](#method2)\n",
    "    1. [Method 3: Asynchronous REST API Calls](#method3)\n",
    "1. [Conclusion](#Conclusion)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook, walks you through how to leverage the containerized deployment of a model or decision to score data. Data is passed to the container and results are returned using a REST API. You need a few things to make that REST API call. First, you need the container endpoint for the model or decision. This notebook goes over how to find that endpoint from the kubeconfig file and the published model or decision name. Next, your data must be in JSON format. This notebook also goes over how to take data from a CSV file and create a list of JSON-formatted transactions for each row of input data. With the endpoint and JSON-formatted data, you are ready to make the REST API call to score your data. The container scores a single row of data at a time, which is not an issue for on-demand scoring. For batch scoring, you can pass data to the container row-by-row, which can be a time consuming process. To speed up scoring batch data, you can make your requests in parallel or asynchronously. This notebook highlights all three methods so that you can use what works best for your use case. These methods are not specific to SAS or containerized deployments, but rather are methods for making multiple REST calls at once.\n",
    "\n",
    "***\n",
    "## Gather Resources \n",
    "First, import all the Python packages that you need to use. Depending on which parts of the notebook you are using, you might not need every package listed below. Thus, you can import only what you need to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Packages for Interacting with APIs and Input Data\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Packages for Using the Kubeconfig File to Find the Endpoint\n",
    "from Kubernetes import client, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Packages for Making REST API Calls in Parallel\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Packages for Making REST API Calls Asynchronously \n",
    "import asyncio\n",
    "import aiohttp\n",
    "from aiohttp.client import ClientSession\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-western",
   "metadata": {},
   "source": [
    "***\n",
    "## Find the Container Endpoint\n",
    "If you already know your container endpoint, you can run the first block of code and enter your container scoring endpoint. Otherwise, please create a directory in the same location as this notebook and name it _config_ and then upload your kubeconfig file into this directory and name it _kubeconfig_. [Click here](https://docs.microsoft.com/en-us/azure/aks/control-kubeconfig-access) for documentation about how to get the kubeconfig file from Azure Kubernetes Service. \n",
    "Next, run the second block of code and enter the kubeconfig context, the port number and the deployed model or decision container name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this block if you already know the scoring endpoint for your container.\n",
    "scoredEndPoint = input(\"Container scoring endpoint: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this block if you are using the kubeconfig file to find the scoring endpoint for your container.\n",
    "context = input(\"Kubeconfig context: \")\n",
    "port_number = input(\"Service port number: \")\n",
    "deployed_name = input(\"Deployed model or decision name: \")\n",
    "\n",
    "config.load_kube_config('config/kubeconfig', context=context)\n",
    "serviceName = deployed_name + \"-service\"\n",
    "\n",
    "# Get the IP address of the container.\n",
    "v1 = client.CoreV1Api()\n",
    "pod_list = v1.list_namespaced_service(\"default\")\n",
    "for pod in pod_list.items:\n",
    "    # print(pod.metadata.name)\n",
    "    if pod.metadata.name == serviceName:\n",
    "        selectedPod = pod\n",
    "        break\n",
    "    \n",
    "podAddr = selectedPod.status.load_balancer.ingress[0].ip\n",
    "    \n",
    "containerUrl = \"http://\" + podAddr + \":\" + port_number\n",
    "r = requests.get(containerUrl + \"/__env\") \n",
    "for endpoint in r.json()['endpoints']:\n",
    "    # print(endpoint)\n",
    "    if (endpoint.endswith(\"/execute\")):\n",
    "        scoredEndPoint = containerUrl + endpoint\n",
    "\n",
    "print(\"Container Scoring Endpoint: \", scoredEndPoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-south",
   "metadata": {},
   "source": [
    "*** \n",
    "## Prepare Data\n",
    "You now have your scoring endpoint. Next, you need to prepare your data in a JSON format. The following code block takes a CSV file and converts it into a JSON list, where each item in the list is one row of data from the CSV table. Please ensure that the column names in the CSV table match the input names that the deployed model or decision is expecting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = input(\"CSV File with Path: \")\n",
    "df = pd.read_csv(csv_path)\n",
    "jsonFile = df.to_json(orient='records', lines=True)\n",
    "jsonList = jsonFile.split('\\n')\n",
    "del jsonList[len(jsonList)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-jewel",
   "metadata": {},
   "source": [
    "***\n",
    "## Make REST API Calls\n",
    "Your data is now correctly formatted, so you are ready to make the REST API call. As mentioned in the introduction to the notebook, you have a few options for how you can send the requests to the container. The first method sends each request one-at-a-time for each row/transaction and waits for a response back from the container before sending the next request. This method works well if you are looking to score just one or a few transactions. The next method uses parallelization to send multiple requests at once. This method makes a separate call from each CPU and can speed up processing time for larger data sets. The last method makes an asynchronous call, which makes all the requests one after the other, and then waits for the container to return the responses back. This method can drastically speed up processing time, but your requests can return out of order. Each option is included below so that you can determine which best works for your use case.\n",
    "\n",
    "<a id=\"method1\"></a>\n",
    "\n",
    "### Method 1: Sequential REST API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Content-Type':'application/json'}\n",
    "results = []\n",
    "for x in jsonList:\n",
    "    response = requests.post(scoredEndPoint, data=x, headers=headers)\n",
    "    response = response.json()\n",
    "    results.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-antigua",
   "metadata": {},
   "source": [
    "Review the first response as a sanity check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-secretariat",
   "metadata": {},
   "source": [
    "<a id=\"method2\"></a>\n",
    "### Method 2: Parallel REST API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus = int(input(\"Number of CPUs: \"))\n",
    "cpus = int(cpus)\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "results = []\n",
    "\n",
    "def score(data_json):  \n",
    "    response = requests.post(scoredEndPoint, data=data_json, headers=headers)\n",
    "    response = response.json()\n",
    "    return response\n",
    "\n",
    "with Pool(processes=4) as pool:\n",
    "        for x in pool.imap_unordered(score, jsonList):\n",
    "            results.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-spirituality",
   "metadata": {},
   "source": [
    "Review the first response as a sanity check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-pencil",
   "metadata": {},
   "source": [
    "<a id=\"method3\"></a>\n",
    "### Method 3: Asynchronous REST API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "async def postData(url:str, data:list, session:ClientSession):\n",
    "    headers = {'Content-Type':'application/json'}\n",
    "    async with session.post(url, data=data, headers=headers) as response:\n",
    "        results= await response.json()\n",
    "        return result\n",
    "\n",
    "async def postAll(data:list):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for row in data:\n",
    "            task = asyncio.ensure_future(postData(url=scoredEndPoint,\n",
    "                                                  data=row,\n",
    "                                                  session=session))\n",
    "            tasks.append(task)\n",
    "        allPostCalls = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    return allPostCalls\n",
    "\n",
    "tasks = asyncio.run(postAll(jsonList))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-reproduction",
   "metadata": {},
   "source": [
    "Review the first response as a sanity check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-majority",
   "metadata": {},
   "source": [
    "***\n",
    "## Conclusion\n",
    "And just like that you can score data using a model or decision deployed into a container. Using the methods listed in this notebook, you can easily incorporate modeling and decisioning into applications and processes. \n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce6558fedf706f51c4ca2efe20bebb372855dd3816f2e5f9b209f35a4122823b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
