{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Copyright Â© 2020, SAS Institute Inc., Cary, NC, USA.  All Rights Reserved.\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Build and Import a Trained Model into SAS Open Model Manager\n",
    "\n",
    "This notebook provides an example of how to build and train a Python model and then import the model into SAS Open Model Manager. Lines of code that must be modified by the user, such as directory paths are noted with the comment \"_Changes required by user._\".\n",
    "\n",
    "_**Note:** If you download only this notebook and not the rest of the repository, you must also download the hmeq.csv, hmeqPrediction.csv, and dmcas_fitstat.csv files from the [/samples/Python_Models/DTree_sklearn_PyPickleModel/Data](../samples/Python_Models/DTree_sklearn_PyPickleModel/Data) directory. These files are used when executing this notebook example._\n",
    "\n",
    "Here are the steps:\n",
    "\n",
    "1. Build and train a model.\n",
    "2. Serialize the model into a pickle file and deploy the pickle file into SAS Open Model Manager.\n",
    "3. Write JSON files associated with the trained model and write the score code .py file. Also, write JSON files for one of the following data options:\n",
    "   (a) Generate Fit Statistics from user-defined input.\n",
    "   (b) Calculate Fit Statistics, ROC curve and Lift curve from data.\n",
    "4. Write a score code Python file for model scoring in SAS Open Model Manager.\n",
    "5. Zip the pickle, JSON, and score code files into an archive file.\n",
    "6. Import the ZIP archive file to SAS Open Model Manager via an API call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Step 1: Build and Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.tree as tree\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dataFolder = Path.cwd() / '../samples/Python_Models/DTree_sklearn_PyPickleModel/Data/' # Changes required by user.\n",
    "zipFolder = Path.cwd() / '../samples/Python_Models/DTree_sklearn_PyPickleModel/Model/' # Changes required by user.\n",
    "modelPrefix  = 'hmeqClassTree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "yName = 'BAD'\n",
    "catName = ['JOB', 'REASON']\n",
    "intName = ['CLAGE', 'CLNO', 'DEBTINC', 'DELINQ', 'DEROG', 'NINQ', 'YOJ']\n",
    "\n",
    "inputData = pd.read_csv((Path(dataFolder) / 'hmeq.csv'), sep=',',\n",
    "                        usecols=[yName]+catName+intName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "useColumn = [yName]\n",
    "useColumn.extend(catName + intName)\n",
    "inputData = inputData[useColumn].dropna()\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(inputData, inputData[yName],\n",
    "                                                test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5,\n",
    "                                    min_samples_split=20,\n",
    "                                    min_samples_leaf=10,\n",
    "                                    random_state=42)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = pd.get_dummies(xTrain[catName].astype('category'))\n",
    "x = x.join(xTrain[intName])\n",
    "y = yTrain.astype('category')\n",
    "trainedModel = model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "yCategory = y.cat.categories\n",
    "outputVar = pd.DataFrame(columns=['EM_EVENTPROBABILITY', 'EM_CLASSIFICATION'])\n",
    "outputVar['EM_CLASSIFICATION'] = yCategory.astype('str')\n",
    "outputVar['EM_EVENTPROBABILITY'] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Step 2: Serialize a Model Into a Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pzmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pzmm.PickleModel.pickleTrainedModel(trainedModel, modelPrefix, zipFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Step 3: Write JSON Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "JSONFiles = pzmm.JSONFiles()\n",
    "JSONFiles.writeVarJSON(inputData[catName+intName], isInput=True, jPath=zipFolder)\n",
    "\n",
    "JSONFiles.writeVarJSON(outputVar, isInput=False, jPath=zipFolder)\n",
    "\n",
    "modelName = 'Home Equity Loan Classification Tree'\n",
    "JSONFiles.writeModelPropertiesJSON(modelName=modelName,\n",
    "                                   modelDesc='',\n",
    "                                   targetVariable=yName,\n",
    "                                   modelType='tree',\n",
    "                                   modelPredictors=(catName + intName),\n",
    "                                   targetEvent=yCategory[1].astype('str'),\n",
    "                                   numTargetCategories=len(yCategory),\n",
    "                                   eventProbVar='EM_EVENTPROBABILITY',\n",
    "                                   jPath=zipFolder,\n",
    "                                   modeler='sasdemo')\n",
    "\n",
    "JSONFiles.writeFileMetadataJSON(modelPrefix, jPath=zipFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# (a) Writes Fit Statistics to dmcas_fitstat.json file from user-defined input.\n",
    "# This cell can be skipped if calculating statistics automatically from data.\n",
    "fitStatTuples = [('GAMMA', 1.65412, 'TRAIN'),\n",
    "                 ('NObs', 176, 'TEST'),\n",
    "                 ('MCLL', .196882, 'VALIDATE')]\n",
    "csvPath = dataFolder / 'dmcas_fitstat.csv' # Changes required by user.\n",
    "JSONFiles = pzmm.JSONFiles()\n",
    "JSONFiles.writeBaseFitStat(csvPath=csvPath,\n",
    "                           jPath=zipFolder,\n",
    "                           userInput=True,\n",
    "                           tupleList=fitStatTuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# (b) Calculates Fit Statistics, ROC curve and Lift curve from data to create the relevant JSON files.\n",
    "# This cell can be skipped if statistics were defined by the user,\n",
    "targetName = 'BAD'\n",
    "targetValue = 1\n",
    "csvPath = dataFolder / 'hmeqPrediction.csv'\n",
    "df = pd.read_csv(csvPath)\n",
    "yTrainActual = df.yActual.to_list()\n",
    "yTrainPredict = df.yPredict.to_list()\n",
    "data = [(None, None),\n",
    "        (yTrainActual, yTrainPredict),\n",
    "        (None, None)]\n",
    "JSONFiles = pzmm.JSONFiles()\n",
    "JSONFiles.calculateFitStat(data, zipFolder)\n",
    "JSONFiles.generateROCStat(data, targetName, zipFolder)\n",
    "JSONFiles.generateLiftStat(data, targetName, targetValue, zipFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Step 4: Generate Score Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ScoreCode = pzmm.ScoreCode()\n",
    "\n",
    "df = pd.read_csv(dataFolder / 'hmeq.csv') # Changes required by user.\n",
    "inputDF = df.drop(['BAD', 'LOAN', 'MORTDUE', 'VALUE'], axis=1)\n",
    "targetDF = df['BAD']\n",
    "ScoreCode.writeScoreCode(inputDF, targetDF, modelPrefix,\n",
    "                         '{}.predict({})', modelPrefix + '.pickle',\n",
    "                         pyPath=zipFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Step 5: Zip Model and Relevant Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pzmm.ZipModel.zipFiles(fileDir=zipFolder, modelPrefix=modelPrefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Step 6: Import Model into SAS Open Model Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "host = 'myserver.com' # Changes required by user.\n",
    "ModelImport = pzmm.ModelImport(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zPath = Path(zipFolder) / (modelPrefix + '.zip')\n",
    "ModelImport.importModel(modelPrefix, projectName='HMEQ', zPath=zPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
